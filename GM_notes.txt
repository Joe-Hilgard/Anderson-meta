3/8/2015
Got the full data. 
Noticed another error in the old data: For study 1 of Greitemeyer:McLatchie:2011, in-group and out-group are just intermediate things used to make a difference score which is supposed to be the "real" effect. These were instead entered as unique subgroups of independent subjects.
Noticed that Saleem Anderson Gentile 2012 entered specific contrasts as having precision of full N (e.g violent-vs-neutral, prosocial-vs-neutral)

1/27/2015

I'm finally going to do Krcmar & Lachlan now
I obtain z = .36, .34, .71 for physAgg, verbAgg, arousal. SE(z) is .0766965
Aggregating directly from how G&M entered it I get smaller effects and smaller SEs
z = .261 for Agg, z = .62 for arousal. SE(z) is 0.062 or 0.059. That seems like a small difference but is 80-120 subjects!

Sestir & Bartholow (2006) has only the one subgroup's effect size entered but has precision commensurate with entire sample.

Wonder where the other 105 subjects are from Saleem, Anderson & Gentile (2012)? Are they on the "prosocial media" spreadsheet that was kept from me?

1/20/2015

I have spent too long trying to reproduce the way that CMA calculates the standard error of Fisher's z. This has been a point of contention between me and Mugge. I understand StdErr(z) as 1/sqrt(n-3). CMA calculates it through the following process:

# d->r
r = d / sqrt(d ^ 2 + a) = 0,832 # where a is (n1+n2)^2 / (n1*n2), a is 4 if n1=n2 
StdErr.r = sqrt(a^2 * StdErr.d ^ 2 / ((d ^ 2 + a) ^ 3)) # don't understand this
# I think this step shrinks StdErr.r a lot when d is large
# r->z
FisherZ = 0.5 * log((1 + r) / (1 - r))
StdErr.z = StdErr.r / (1 - r ^ 2)
# I think this last step inflates StdErr.z a little as r increases
# Net effect is that larger effect sizes yield smaller StdErr.z relative to smaller effect sizes

Reading Borenstein et al textbook, it seems like var(d) should increase with d. Larger d means more uncertainty in estimate of s (but in in x1-x2). Some argument as to whether denominator of var(d) is 2(n1+n2) or 2(n1+n2-2).
I have carefully read the relevant chapters of Borenstein et al. and there is no mention of this equation for getting StdErr.r from d and StdErr.d. If anything, it looks like larger effects should have greater variance, not greater precision. Borenstein et al. seem insistent that var(z) is simply 1/(n-3).

This is potentially hazardous if big effects are given greater undeserved precision.
Mugge argues that CMA is doing fine and that I'm off. Often by as much as 8% or more in SE, sometimes almost half again the samle size.

I'd take their word for it, but I'm not having this issue in Craig's meta-analysis, where the standard error is reliably 1/sqrt(n-3) 

Update: Other sources for 1/sqrt(N-3):
this U of I lecture: http://courses.education.illinois.edu/EdPsy580/lectures/correlation-ha.pdf
webpage: http://davidmlane.com/hyperstat/A50760.html
Hayes textbook
Borenstein textbook


1/20/2015

AggAff:
-Fischer et al. 2012 S2 is outlier among AggAff experiments. Sign is correct, but I wonder if hypothetical "would you feel bad for egoistic behavior" is aggressive affect.
-Shafer (2012) and Saleem&Anderson have largest sample sizes: accurate?

Arousal:
-Krcmar et al is all wrong, huge r and huge n due to clumsy combination of pairwise comparisons
-lots of heterogeneity, need to check it out
-when I combine Arriaga by hand I get .346 not .379. May be something wrong happening in combine.rows()?

AggBeh:
- naive meta estimate is r=.25 which is much too large
- Hasan, Begue, & Bushman entered with "hostile expectation bias" (2012) as a form of aggressive behavior (bad!)
- Another enormous effect, Greitemeyer & McLatchie (2011) S2 "other player's aggressive behavior". Seems that they're trying to say "aggressive behavior towards other participant". ns for S1 seem a little off: not n=40, not n=60. S2 std.err is too small, reflects n=53 or n=57 instead of n=40. standard error is 10% smaller than it should be. "Other player's secondary emotion" cherry-picked for agg cog, human uniqueness / human nature stuff discarded.





==========
12/28/14 notes

General CMA notes:
- Multiple subgroups can be imputed across to create a "combined" estimate
  I believe this sums the Ns and makes a weighted average effect size.
- For multiple outcomes, CMA allows the following options:
  - Use the mean of all outcomes
  - Use each outcome, assuming independence
  - Use the first outcome available based on some sequence
- I wonder which settings Craig used? Which settings G&M used?

Krahe & Moller, 2011
-Aggressive behavior male & female have been reversed.
Was male r = .17, female r = .09,
Should be male r = .09, female r = .17.
-Each simple slope is entered as having N=1688, 
rather than 837 for females and 851 for males.
It may be a problem because CMA will impute a
"Combined" sample with too much precision (CMA manual, p 52).
It may not be a problem because CMA will average, not sum, for outcomes.
--However, note that it's impossible to reproduce which 
  checkboxes were ticked (CMA manual, p. 54)
-Should prosocial behavior be entered as negative?

Krahe, Busching, Moller, 2012
I'm having trouble finding the "teacher-rated aggression" outcome at timepoint T1 r = -.09

Anderson & Carnagey, 2011
"High intensity aggression" is coming up with SE =.343, N=11.5, which surely isn't right

Krcmar & Lachlan, 2009
Apparent Ns vary across outcomes within a condition by as much as 10-20 n
Ns seem a little too high (e.g. 61 instead of 58 for 30min, 82 instead of 57 for 10min)
Entering each pairwise effect size w/r/t control group with precision of 60+, 80+ seems to maybe over-count control group? Because subgroup-within-study is summed across. so a study of N=173 will end up entered as N=250+


Sometimes Subgroup.within.study needs combining samples (e.g. Valadez & Ferguson, 2012) and sometimes it doesn't (e.g. Anderson & Carnagey?).
Ewoldsen?

