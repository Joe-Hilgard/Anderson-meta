
<!-- saved from url=(0039)http://www.p-curve.com/app3/pcurve3.php -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" type="text/css" href="./AggCog_Exp_1_files/style2.css">
<title>Results p-curve App 3.01</title>
</head>

<body><div width="1200"><font size="6" face="calibri"><center><b><i>P</i>-CURVE RESULTS - App 3.01<br><font size="2" color="grey">App's Last Update: 2015 04 13</font></b></center><br></font></div><p><font size="6" face="calibri"><font size="7">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</font>	<img src="./AggCog_Exp_1_files/1446920994.png" height="560 width=" 700"="" border="0">
<table style="text-align: left;" border="0" cellpadding="0" cellspacing="0" height="237" width="900">
<tbody>
<!-- HEADER IN TABLE --"STATISTICAL INFENRENCE == RESULTS-->
	<tr>
	   <td style="font-weight: bold; text-align: center; width: 399px; font-family: Calibri; background-color: rgb(204, 204, 204);">
	        <big>Statistical Inference</big></td> 
	   <td colspan="2" rowspan="1" style="text-align: center; font-weight: bold; width: 238px; font-family: Calibri; background-color: rgb(204, 204, 204);">
	       <big>Results</big></td>
	</tr>

<!-- 2ND HEADER--"BINOMIAL AND STOUFFER METHOD -->
	<tr>
   		<td style="text-align: center; width: 399px; font-family: Calibri; background-color: rgb(204, 204, 204);"><br> </td>
		   <td style="text-align: center; width: 238px; font-family: Calibri; background-color: rgb(204, 204, 204);"><b>Binomial Test</b><br> 
	         <small><i>(Share of significant results p&lt;.025)</i></small></td>
		   <td style="font-family: Calibri; background-color: rgb(204,204, 204);"> <div style="text-align: center;">              <b>Continuous Test</b><br></div>
	                                                                                                                   <small><i>(Aggregate pp-values via Stouffer Method)</i></small></td> 
	</tr>

<!-- RIGHT SKEW RESULTS -->
	<tr class="border_bottom">
		<td style="width: 399px; font-family: Calibri;">1) Studies contain evidential value.<br> 
                                <small><i>&nbsp; &nbsp; &nbsp; (Right skew)</i></small></td>
		<td style="width: 238px; text-align: center; font-family: Calibri;" align="center" bgcolor="#ffffff"><span style="color: rgb(0, 0, 0); font-size: medium;">
		<i>p</i> =.1051</span></td> 
		<td style="width: 237px; font-family: Calibri; text-align: center;"><span style="color: rgb(0, 0, 0); font-size:medium;">Z = -4.42,&nbsp;<i>p</i>&lt;.0001 </span></td>
	</tr>

<!-- 33% POWER RESULTS -->
	<tr class="border_bottom">
		<td style="width: 399px; font-family: Calibri;">2) Studiesâ€™ evidential value, if any, is inadequate. <br> 
			<small><i>&nbsp; &nbsp; &nbsp;(Flatter than 33% power)</i></small></td> 

		<td style="width: 238px; font-family: Calibri;" align="center"><i>p</i> =.5134</td>
		<!-- COMMENTED OUT EXPECTED VS OBSERVED 	<br>	<font color="#999999"><i><small>(expected: 74%, observed: 72%)</small></i></font></td> -->
		<td style="width: 237px; font-family: Calibri; text-align: center;"><span style="color: rgb(0, 0, 0); font-size: medium;">Z = 1.65,&nbsp;<i>p</i>=.9503 </span></td>
	</tr>	

<!-- LEFT SKEW RESULTS -->
	<tr> 
		<td style="width: 399px; font-family: Calibri;">3) Studies exhibit evidence of intense <i>p</i>-hacking.
					<br><small><i>&nbsp; &nbsp; &nbsp;(Left skew)</i></small></td>
		<td style="width: 238px; font-family: Calibri;" align="center"><i>p</i> =.9616</td>
		<td style="width: 237px; font-family: Calibri; text-align: center;">Z = 4.42, <i>p</i>&gt;.9999		</td>
	</tr>

<!-- POWER HEADER -->
	<tr>
	<td colspan="3" rowspan="1" style="width: 238px; font-family:Calibri;" align="center" bgcolor="#cccccc"><big><b>Estimate of Statistical Power</b></big></td>
	</tr>

<!-- POWER RESULTS -->
	<tr class="border_bottom">
		<td valign="top" style="width: 238px; font-family:Calibri;">Average power of tests included in <i>p</i>-curve<br> <small><i>&nbsp;&nbsp;&nbsp; (correcting for publication bias)</i></small><br>
		</td>
		<td align="center" valign="middle">50%<br>
		</td>
		<td><br></td>
	</tr>
</tbody>
</table>
</font></p><p style="font-family:Calibri;"><font size="6" face="calibri">

	</font>The observed <i>p</i>-curve includes 16
 significant results (p&lt;.05), of which 68.8% are p&lt;.025.<br>There were 8
additional results entered but excluded from <i>p</i>-curve becuase they were <i>p</i>&gt;.05.	<br><br></p><hr>
	<div style="width:900" ;="" align="justify">
	<!-- CUMULATIVE P-CURVES -->
	<p><b><font size="5" face="calibri">Dropping Highest/Lowest p-values</font><br></b><font size="3" color="gray"><i>(Cumulative meta-analysis)</i></font><br>
	<font size="3">
	In order to assess the extent to which p-curve's overall results hinge on a few studies, the figure below reports them
	excluding a progressively larger number of the most extreme p-values originally included in p-curve. <br><br>
	The first column of charts, reports results that first exclude the smallest p-value in p-curve, then the second smallest, and so on.<br>
	For example, if p-curve contained the following four p-values: p=.001, p=.004, p=.01 and p=.045, the 1st marker would report results with all four p-values, 
	the next marker when one excludes p=.001, then excluding both p=.001 and p=.004, and so on.<br><br>
	In the second column one proceeds in opposite order. First excluding p=.045, then p=.045 and p=.01, and so on.<br><br>
	For completeness the graph plots what happens until there is only one p-value left, but in most situations one is only interested on what happens as the 
	single or handful of most extreme p-values are excluded.<br> We should place more confidence in sets of studies whose overall evidential value survives the
	exclusion of the most extreme few results.<br><br>
	
	</font></p><p><font size="3"><img src="./AggCog_Exp_1_files/1446920994_cumulative.png" height="700" width="700" border="1"></font></p><font size="3">	
	
	</font><font size="5" face="calibri">
	<br><br><hr>
	</font><p><font size="5" face="calibri"><b>Brief Explanations of Main Results:</b></font><br>
	<font face="calibri" size="3">
	1) <b>Binomial tests</b> compare the observed proportion of significant results that are p&lt;.025 (in this case: 69%) to the expected proportions 
		  when there is no effect (50%), and when studies have 1/3 power (71%). This latter number (71%) varies (by a few %s) 
		  as a function of the degrees of freedom of the tests entered to <i>p</i>-curve.<br><br>
	
	2) <b>Continuous tests</b> are obtained by computing <i>pp</i>-values for each test (probability of at least as extreme a p-value conditional on p&lt;.05), and converting them to Z scores(N(0,1)) 
	      The sum of these (16
 in this case) Z scores, divided by the square-root of the number of tests included (again: 16
 in this case) 
		  is the reported Z score in that column (and corresponding p-value).   This approach is known as Stouffer's Method (read text in <font color="gray">gray</font> below for more information).<br> 
		  <br>
		  Note that the binomial and continuous tests are by definition one-sided (e.g., <i>more</i> right skewed than flat). We use negative Z values to indicate 
		  deviation in the direction of the alternative of interest;  for example a negative Z value for the Right-Skew test is evidence against the flat null, in 
		  favor of Right-Skew.<br><br>
		  
	3) <b>Statistical power</b> is obtained by comparing the expected <i>p</i>-curve for each possible value of power between 5% and 99% to the observed <i>p</i>-curve, and selecting
	   the level of power that leads to the expected <i>p</i>-curve that most closely resembles the observed <i>p</i>-curve (we quantify the similarity with Kolmogorv-Smirnov's D statistic). <br><br>
	
	<b><font color="gray">Note: Why do you now see Z-scores instead of chi-square values in the Statistical Inference table above?</font></b><font color="gray">
	 <br>In our <i>p</i>-curve <a href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2256237">paper</a>, and previous versions of this app, we combined the pp-values using Fisher's 
	 rather that Stouffer's method (Fisher's method results in an overall chi-square rather than Z score result). <br>
	 We now prefer Stouffer's method because it is more sensitive to consistent mild departures from the null, and less sensitive to occasional extreme departures (e.g., a single p=.04999 or p=.0000001). 
	 See pages 66-68 in Abelson's "Statistics as a Principled Argument" <a href="http://web.archive.org/web/20150226162844/https://books.google.com/books?id=yQLFl1ILjZwC&lpg=PP1&dq=statistics%20principled%20argument&pg=PA66#v=onepage&q=statistics%20principled%20argument&f=false">
	 book</a>. We have re-run all analyses in our published paper using Stouffer's method and the results, importantly those of overall power (Figure 6 in the paper), are very similar:
	 (<a href="http://p-curve.com/Supplement/Comparing%20Stouffer%20to%20Fisher's%20method%20-%202015%2003%2002.pdf">.pdf</a>).
   	</font>
	
	</font></p><font face="calibri" size="3">
	</font></div><font face="calibri" size="3">

<br><br><hr>


	

<div id="individual-vals">
<p><b><align="left"><font size="5">Calculations for each test entered into <i>p</i>-curve:</font></align="left"></b><br>
Note: The R Code necessary to carry out all calculations is <a href="http://p-curve.com/Supplement/Rcode_other/R%20Code%20behind%20p-curve%20app%203.0%20-%20distributable.R">available here</a>.<br><br>
<table style="border:1px solid black;border-collapse:collapse;">
	<thead>
		<tr>
			<th rowspan="2">Test entered <br>by user</th>
			<th rowspan="2">recalculated p-value</th>
			<th colspan="3" class="center"><i>pp</i>-values</th>	
			<th colspan="3" class="center">Z Scores</th>
  	      </tr>
		<tr>
			<th>right-skew</th>
			<th>left skew</th>
			<th>power of 33%</th>
			<th>right-skew</th>
			<th>left skew</th>
			<th>power of 33%</th>
		</tr>


	</thead>
	<tbody>
		<tr align="center">
		  <td align="left"> t(128)=2.11146324713012 </td>
		  <td> .03668 </td>
		  <td> .73354 </td>
		  <td> .26646 </td>
		  <td> .13849 </td>
		  <td> 0.62 </td>
		  <td> -0.62 </td>
		  <td> -1.09 </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(98)=1.96592554007763 </td>
		  <td> p&gt;.05 </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(42)=2.58636449591172 </td>
		  <td> .01326 </td>
		  <td> .26512 </td>
		  <td> .73488 </td>
		  <td> .50075 </td>
		  <td> -0.63 </td>
		  <td> 0.63 </td>
		  <td> 0.00 </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(62)=0.297714623632603 </td>
		  <td> p&gt;.05 </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(217)=3.73968069740936 </td>
		  <td> .00024 </td>
		  <td> .00472 </td>
		  <td> .99528 </td>
		  <td> .95441 </td>
		  <td> -2.60 </td>
		  <td> 2.60 </td>
		  <td> 1.69 </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(165)=2.48704065888832 </td>
		  <td> .01388 </td>
		  <td> .27751 </td>
		  <td> .72249 </td>
		  <td> .47637 </td>
		  <td> -0.59 </td>
		  <td> 0.59 </td>
		  <td> -0.06 </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(118)=0.419896963015073 </td>
		  <td> p&gt;.05 </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(22)=1.80551637076177 </td>
		  <td> p&gt;.05 </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(50)=1.6689191215366 </td>
		  <td> p&gt;.05 </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(194)=2.09828884070063 </td>
		  <td> .03717 </td>
		  <td> .74348 </td>
		  <td> .25652 </td>
		  <td> .13227 </td>
		  <td> 0.65 </td>
		  <td> -0.65 </td>
		  <td> -1.12 </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(126)=2.63248775085948 </td>
		  <td> .00954 </td>
		  <td> .19073 </td>
		  <td> .80927 </td>
		  <td> .57421 </td>
		  <td> -0.88 </td>
		  <td> 0.88 </td>
		  <td> 0.19 </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(109)=2.58902744250041 </td>
		  <td> .01094 </td>
		  <td> .21875 </td>
		  <td> .78125 </td>
		  <td> .54173 </td>
		  <td> -0.78 </td>
		  <td> 0.78 </td>
		  <td> 0.10 </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(116)=3.31922797038647 </td>
		  <td> .00121 </td>
		  <td> .02413 </td>
		  <td> .97587 </td>
		  <td> .87450 </td>
		  <td> -1.98 </td>
		  <td> 1.98 </td>
		  <td> 1.15 </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(64)=2.16333258685519 </td>
		  <td> .03426 </td>
		  <td> .68513 </td>
		  <td> .31487 </td>
		  <td> .16887 </td>
		  <td> 0.48 </td>
		  <td> -0.48 </td>
		  <td> -0.96 </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(112)=2.11617302513969 </td>
		  <td> .03655 </td>
		  <td> .73090 </td>
		  <td> .26910 </td>
		  <td> .14024 </td>
		  <td> 0.62 </td>
		  <td> -0.62 </td>
		  <td> -1.08 </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(11)=1.84866418416761 </td>
		  <td> p&gt;.05 </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(48)=2.14986833468291 </td>
		  <td> .03663 </td>
		  <td> .73267 </td>
		  <td> .26733 </td>
		  <td> .14168 </td>
		  <td> 0.62 </td>
		  <td> -0.62 </td>
		  <td> -1.07 </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(205)=5.54448215250843 </td>
		  <td> &lt;.00001 </td>
		  <td> &lt;.00001 </td>
		  <td> &gt;.9999 </td>
		  <td> .99983 </td>
		  <td> -4.63 </td>
		  <td> 4.63 </td>
		  <td> 3.58 </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(136)=0.0348569546869818 </td>
		  <td> p&gt;.05 </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(222)=2.71151316033483 </td>
		  <td> .00722 </td>
		  <td> .14444 </td>
		  <td> .85556 </td>
		  <td> .63276 </td>
		  <td> -1.06 </td>
		  <td> 1.06 </td>
		  <td> 0.34 </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(241)=1.88375345552512 </td>
		  <td> p&gt;.05 </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  <td> - </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(88)=3.95153415735131 </td>
		  <td> .00016 </td>
		  <td> .00313 </td>
		  <td> .99687 </td>
		  <td> .96750 </td>
		  <td> -2.73 </td>
		  <td> 2.73 </td>
		  <td> 1.85 </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(69)=3.87368531219512 </td>
		  <td> .00024 </td>
		  <td> .00482 </td>
		  <td> .99518 </td>
		  <td> .95773 </td>
		  <td> -2.59 </td>
		  <td> 2.59 </td>
		  <td> 1.72 </td>
		  
		</tr>
		
	
			
	
	
	</tbody><tbody>
		<tr align="center">
		  <td align="left"> t(196)=3.44773509636571 </td>
		  <td> .00069 </td>
		  <td> .01384 </td>
		  <td> .98616 </td>
		  <td> .90952 </td>
		  <td> -2.20 </td>
		  <td> 2.20 </td>
		  <td> 1.34 </td>
		  
		</tr>
		
	
			
		<tr align="center">
		<td colspan="5" bgcolor="#CCC"><b>SUM of Z-Scores in column, dividing by sqrt(N of tests) - Stouffer's Method-----&gt;</b></td>
		<td>-4.42</td>
		<td>4.42</td>
		<td>1.65</td>
	</tr>
						 
</tbody></table>


	</p><div align="justify" style="width:900" ;="">
	<p><b>Explaining these calculations with an example:</b><br>
	Take the first significant result entered: <b>t(128)=2.11146324713012</b>. 
	A two-sided test obtaining that test value has a p-value of <b>0.03668</b>.<br>
	<i>pp</i>-values are the probability of at last as extreme a significant p-value. For right and left skew we compute these under the null 
	of no effect; becuase p-values would be distributed uniform between 0 and .05, we simply divide by .05 (multiply by 20) and get the <i>pp</i>-value for right skew,
	that is 0.03668*20=<b>0.73354</b>. One minus that  gives us the <i>pp</i>-value for left skew <b>0.26646</b>.<br><br>
	For the <i>pp</i>-value under the null that the test is powered to 33% things are a bit more complicated. This explanation will not be quite enough, but: we find the non-centrality parameter for the 
	corresponding distribution and degrees of freedom that gives 33% power.	We then evaluate in that non-central distribution the observed test statistic, t(128)=2.11146324713012, and now divide by 33% rather than 5% 
	because now 1/3 of tests are expected to be p&lt;.05 rather than only 5% of them. <br><br>More importantly, the interpretation of the <i>pp</i>-value for 33% power is as follows. If the underlying effect size were big enough 
	to give the sample of the study obtaining t(128)=2.11146324713012 33% power, then with probability <b>0.13849</b> we would get a p-value of 0.03668 or higher. <br><br>
	The last three columns report the Z-Scores that give rise to the <i>pp</i>-values from the previous columns. So for the right-skew <i>pp</i>-value we had p=<b>0.73354</b>, evaluating the
	standard normal distribution in that percentile gives us the reported Z=<b>0.62</b>. Note that because left-skew <i>pp</i>-values are one minus the right skew ones, and the normal
	distribution is symmetrical, the Z-score for left skew is always the same value with opposite sign of that of right skew.<br>

	<br><br><font color="gray">Note: when a p-value or pp-value is smaller than 2.22e-16 the app uses that value instead. 
	The calculations are hence only approximate for extremely significant results (e.g., t(98)=7.12).</font>









<!-- DIAGNOSTIC CHART FOR POWER-->
	<br><br></p><hr><p><font size="5"><b>Diagnostic plot for power estimation</b></font><b><br></b>
	This figure plots how close the expected <i>p</i>-curve gets to the observed <i>p</i>-curve for each level of power between 5% and 99%.
	The y-axis is how far from perfect the fit is for a given level of power.<br><br>
	The table with results at the top of this page reports <b>50%</b> as the estimate of power. The figure below shows that is 
	the level of power that gets us closest to the observed <i>p</i>-curve.<br><br>
	
	If the red dot in the figure is noticeably lower than the other dots, it means that the estimate of power is indeed better fitting than the alternatives.
	The flatter the curve below looks, the less confident you should be in the power estimate, becuase it means that the data are nearly as consistent with
	other levels of power. 
	</p><p><img src="./AggCog_Exp_1_files/1446920994_fit.png" height="350" width="350" border="1">
<br><br></p><hr><br>
<p><font size="5"><b>Relative frequency of p-values depicted in <i>p</i>-curve chart above</b></font>
<br><font size="3"><i>(You can copy-paste them elsewhere (e.g., Excel) to make your own graph)<br></i></font>

<table cellpadding="3px" style="border:1px solid black;border-collapse:collapse;">
	<thead>
		<tr>
			<th>p-value</th>
			<th>observed</th>
			<th>33% power</th>
			<th>uniform</th>
			
  	      </tr>
	</thead>

	
	<tbody>
		<tr align="center">
		  <td> 0.01 </td>
		  <td><font color="blue">  50.0% </font></td>
		  <td><font color="green">   43.6% </font></td>
		  <td><font color="red"> 20% </font></td>
		</tr>

	
	
	</tbody><tbody>
		<tr align="center">
		  <td> 0.02 </td>
		  <td><font color="blue">  18.8% </font></td>
		  <td><font color="green">   19.7% </font></td>
		  <td><font color="red"> 20% </font></td>
		</tr>

	
	
	</tbody><tbody>
		<tr align="center">
		  <td> 0.03 </td>
		  <td><font color="blue">  0.0% </font></td>
		  <td><font color="green">   14.6% </font></td>
		  <td><font color="red"> 20% </font></td>
		</tr>

	
	
	</tbody><tbody>
		<tr align="center">
		  <td> 0.04 </td>
		  <td><font color="blue">  31.3% </font></td>
		  <td><font color="green">   11.9% </font></td>
		  <td><font color="red"> 20% </font></td>
		</tr>

	
	
	</tbody><tbody>
		<tr align="center">
		  <td> 0.05 </td>
		  <td><font color="blue">  0.0% </font></td>
		  <td><font color="green">   10.2% </font></td>
		  <td><font color="red"> 20% </font></td>
		</tr>

	</tbody></table>
	

</p></div></div></font></body></html>