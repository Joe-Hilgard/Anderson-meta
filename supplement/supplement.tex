% Explaining that I'm basically using Peters
One criticism of the Egger and PET-PEESE metaregression tests is that some effect size estimates have an inherent relationship between precision and effect size that is not caused by research bias. For example, given a single sample size, the precision of Cohen's $d$ increases as the effect size $d$ increases. A similar phenomenon holds for odds ratio. When these effect sizes are used, metaregression techniques risk misidentifying the inherent relationship between precision and effect size as a small-study effect. To avoid this problem, it has been suggested that one instead use precision estimates that are a function of the sample size alone (Peters, Sutton, Jones, Abrams, \& Rushton, 2006). In the current report, we use as our effect size estimate Fisher's Z with standard error $\frac{1}{\sqrt{N-3}}$, consistent with the original analysis of Anderson and colleagues. Because this standard error is not a function of the effect size, we avoid the problem of an inherent relationship between precision and effect size that might otherwise contaminate the metaregression.

% When excluding Sigurdsson et al. from full-sample non-experimental agg cog: naive FE r = .15, naive RE r = .17, PET r = .10, PEESE r = ..15, puniform r = .16, pcurve r = .16
A study by \citet{Sigurdsson:etal:2006} seemed to be an outlier among cross-sectional studies of aggressive cognition. This study was coded as not-best-practices and so influences only the full sample analysis. Excluding this study slightly reduced all estimates:  naive FE, $r = .15$; naive RE, $r = .17$; PET, $r = .10$; PEESE, $r = .15$; p-uniform, $r = .16$; p-curve, $r = .16$.